## Sustainable open source software maintenance

This is the equation we're trying to optimize:
![](http://i.imgur.com/JJzZJA8.png)

Open-source maintenance is not the same thing as open-source development, and we need more project leads that care as much about the former as they do about the latter.

## Establish a quality-centric mindset

Having high quality standards for your project is a matter of practicality, not pride. To understand why, it helps to remember that "bad code" is typically hard to understand, hard to test, hard to change, and hard to reuse. No matter how useful your project is to the world right now, poorly written code can get in the way of its future progress.

Once the impact of low quality code reaches a critical mass, the pace of development grinds to a halt, and the temptation is great to either let projects stagnate or to attempt the *big rewrite* with a heavy focus on quality standards. Unfortunately, neither of these outcomes typically end well for a project's existing community of users, because historically speaking the road to maintainer burnout is paved with *big rewrites*.
 
Some will inevitably take these observations as a cautionary tale, and make a solemn promise to themselves and to their community to establish high quality standards for their project from day one; promising to never ship any bad code in their releases, and establishing strict coding guidelines to keep their projects in ship shape at all times. But anyone who has spent enough time down the rabbit hole can tell you that this doesn't really work, either.

Writing high quality code takes time, and you can't be sure that time is well spent until you have a decent understanding of the domain you are working in. In order to quickly build up knowledge about a complex problem space, you need to be able to try out some ideas without allowing quality concerns to slow you down. This approach helps you generate feedback quickly, and what you lose in code quality up front you gain back in insights that can be used to write better code later. The trick is to understand the bargain you are making when doing this, and whether or not the benefits are likely to outweigh the costs. In other words, the path to quality is a balancing act, and it involves making some educated guesses along the way.

If you are too strict with your quality standards, you can miss out on healthy experimentation that will improve your project over the long haul, but if you loosen up too much your project will perpetually remain in an experimental state in which none of its code can be trusted. The sweet spot is somewhere between these two extremes, and it pays to actively seek it out rather than just hope to end up there by chance.

An optimal process is one that always keep the quality arrow pointing upwards over the long haul, but isn't so brittle as to prevent necessary experimentation and the occasional mistake from happening. We'll now discuss a few specific tactics that can help you achieve that goal.


## Let external changes drive internal quality improvements

In an early-stage project, there will be areas of code that are bad because you aren’t yet familiar with the problem domain you are working in. In a more mature project, there will still be “new areas” that are experimental, and you will also have a fair amount of code that has decayed either due to technical drift, shifts in priorities, or just general negligence.

Having some technical debt is only natural on most software projects, and there’s no getting around it unless you have an extremely disciplined team with endless resources and no external pressures. Open-source projects tend to have a much more diverse environment than that, so it is unrealistic to assume that “ideal software practices” will apply to your projects as an open-source maintainer.

The key is to manage the chaos and use your time well. Assume that there will be rough patches, and seek to isolate them when you can, and minimize their impact when you cannot.
An easy way to do that is to simply focus on improving quality wherever you are actively working in the code.

For any non-trivial bug fix or new feature, you will need to work with various components in your system, some that are in decent shape, and others that have fallen into disrepair. If you stop to refactor entire functions and classes every time you encounter bad code along your path, what could be an incremental change will turn into a much bigger project. The work may be worthwhile in its own right, but it may take away from everything else you could be doing to improve 
the project.

Take a moment now to consider the following diagram. In it, the rectangle represents your entire codebase. The light blue regions represent code that is easy to work with, and the pink regions represent code that is difficult to work with. The arrows represent the areas of your project you will need to work on in order to build a feature or fix.

Rather than completely fixing any problematic areas of code we find along the path, we instead refactor just in the immediate area around the work we are doing (represented in dark blue below). In doing so, the problematic areas of the code will get broken up a bit, until eventually it becomes easier to change your software without encountering bad code that slows you down.

![](http://i.imgur.com/PHwPkyD.png)

In practice, this might mean doing simple things like extracting helper methods, or building method objects rather than rewriting and updating the tests for an entire method. Doing this splits one big messy chunk of code into a small section of good code and a slightly smaller section of bad code. As the bad sections become smaller and smaller, it becomes more and more realistic to eliminate them entirely, without spending a large amount of time purely dedicated to 
refactoring and cleanup.

## Increase test coverage and clarity as your project matures

Ensuring 100% test coverage at all times is a noble goal, but is not always practical. Even when full test coverage exists, it is often only a sign that “all the code gets run by the test suite”, and it’s not an indicator of how clear or well-defined the tests themselves are. In the experimental phases of a project, sometimes writing only very loose tests can be a good idea, and in some cases, it’s fine to have no tests at all.

However, test coverage becomes more important as a project matures, because tests set the expectations about how the features of a project are meant to behave. As people write code that depends on features from a library, or as the library itself depends on its own features internally, poorly specified features can easily become broken without the build breaking along with it. These problems will probably not be noticed as soon as the change is introduced, but instead will surface later when someone encounters the problem indirectly.

The effect of inadequate testing is that much of the behavior of a project remains either undefined or held in the head of a handful of people who understand the design ideas behind 
the project. These problems tend to compound over time, and a point is eventually reached where no meaningful changes can be made to a project without breaking something else 
in the process.

* When reviewing a pull request, check to make sure that new behavior has tests, and that they are written precisely enough that you will understand them several months from now. If anything is unclear, discuss it with the submitter and then add additional specs to cover the assumptions.

* Also look to see whether the code depends on existing features that either do not have tests, or have tests that are underspecified. In most cases, adding additional test coverage one layer out will help prevent you from seeing a higher level feature and not understanding why when a low-level feature changes in some subtle way.

* Be extra wary of changes to existing features. Even if the change is covered by tests, the base behavior may not be adequately covered.

* If bugs are encountered while working on integrating a new change, add tests for those as well.

* If the change is a bugfix itself, make sure that it captures the bug at the actual level it is happening at, and not just at the surface level. Usually it makes sense to add a test at two levels: the level it was discovered at, and at the source of the problem. But if you choose only one, pick the source level.

* For a bug fix, create reproducing examples by stripping away layers until you can no longer reproduce an incorrect behavior. Then clarify the correct behavior at that level.

* For a feature, make sure that use cases are clearly defined, if not in the tests then at least in the pull request discussion or an example file. These will help you interpret the intention behind the tests, rather than just the assertions. Augment the specs with any clarifications as needed.

* Even if a pull requests has tests of its own and the full suite passes, is it built on top of code that is poorly tested? If so, there may be built in assumptions that are invalid. Helps to at least push the wall back one level out.

## Consider the ongoing maintenance costs of every change

The quality of a given changeset is not determined simply by its code alone in isolation, but how well it will integrate with the project as a whole. If you are the maintainer of a project, you can’t assume contributors will take these points into account, so it’s up to you to do it.

Helpful guidelines / questions to ask:

- Is this change going to impact other planned changes or work in progress in the immediate future?

- In dev, merge fast and revert fast. Ask questions later. Don't allow repeated "fixes" to destabilize your development branch.

- In stable releases, find the shortest path towards getting bug fix releases out when needed. If this means degrading edge case behavior to make the common use case of a feature stable again, do it. If it means coming up with a workaround until the root issue is dealt with, that’s 
fine too. The longer unresolved issues remains unresolved, the more likely they are 
to accumulate and get in the way of forward development.

- Someone is going to need to take care of this code indefinitely -- No guarantee the original author will be around when a problem occurs months or years later.

- Without historical breadcrumbs, it is hard to get a sense of what the original context of a change was, and also hard to separate the essential details of a change from the incidental implementation details. Atomic commits can help prevent it feeling like you’re looking for a needle in a haystack, and squashed merges (as long as they reference all squashed commits) can help keep your main branch organized at the level of “atomic external changes”





























--------------------------------------------------------------

" I come across a lot of contributions, including bug fixes, that don’t include any tests.  While the contributor has taken the effort to dig through the implementation to discover what was wrong and how to fix it in a minimal way, they didn’t take the effort to see if it was easy to write a test to make sure it stays fixed.  For long-running projects this is especially critical as its all too easy for that small fix to get lost again during a refactor or other maintenance activity."



* Regression testing and test coverage for functional changes

* Emphasize quality along the full lifecycle: write the test at the right level, write the fix in the right way, write good notes to explain the problem.

* Keep a long-running maintenance branch that's separate from development, and make sure fixes get applied there as well
as on the bleeding edge.

* Don't rush to convergence on issues of quality, allow several ideas to be tried out, and quickly abandon old work if better new work comes along. But keep in mind that "better" is good enough, and "more better" can always be accomplished later.
https://github.com/prawnpdf/prawn/pull/600 
Also, balance "improving what you have" with 
"trying out new directions.

* Make it easy to revert or disable broken code. (This has to do with how you use git, not just the fact that you're using it
squashing, atomic commits, etc)

## Limit work in progress

* Delegate and keep contributors unblocked

* Focus on incremental improvement

* Close tickets that need revisions or have gone stale
(but always give a reason)

* Expedite easy changes

* Prioritize the almost done work over the just started work

* Treat the role as maintainer and core developer separately. Don't bury yourself in coding challenges if you don't have someone else helping with maintenance.

* Revise pull requests yourself if they're important enough and the changes are easier done by you than by someone else.

* Treat all incoming requests as prospective work rather than WIP until they are far enough along to commit to wrapping
up yourself.

## Deliver often

* Have a well defined release cycle 
(discuss scoped releases vs. rolling releases)

* Keep your projects in a release-ready state (Prawn has a policy that release notes need to be updated before a pull request is merged)

* Ruthlessly revert on head to minimize instability, so that the code does not need to go through a 'stabilization' process before release.

* Have a clear checklist for your release process.

## Balance demand against throughput

* Have a sense of what your availability is, and focus on making the most progress on the project as a whole with the time available rather than making a single issue perfect. (i.e. understand opportunity costs)

* Github Pulse can give a coarse measure of project throughput, as can release notes.

* Don't make commitments about timeline or specific improvements, instead communicate what needs to be done, and what the current workload is like.

* Allow requests to be identified as stale or blocked after a reasonable time period, and remove them from your backlog.

## Set clear priorities

* Have different level of services for different types of requests, and a clear way of identifying them. (Example: order in Prawn is that we do not track feature requests at all, and work-in-progress bug fixes are prioritized over work-in-progress features)

* Always favor things that are close to being done, i.e. "Always Be Closing"

* Don't spend too much effort on incomplete or underspecified bug reports or pull requests, unless they are more important than other work that you can be doing. Give the feedback of what needs to be addressed, then move on to something else.

* (Low Cost, High Value) > (Low Cost, Low Value) > (High Cost, High Value) > (High Cost, Low Value) -- Tech debt snowball

* Find the intersection between the things that have the most impact and the people who have the right knowledge and availability to solve the problem. Sometimes you can recognize something as urgent without taking urgent action yourself.
Saying "As soon as someone does X I will make sure to free up time to cut a release quickly" is good enough.

* The role of a maintainer is to be responsive and provide necessary administrative support, not necessarily to do the work to solve everyone's problems.


## Improve predictability by attacking sources of variability

Sources of OSS variability:

* Changes that would slow down or block an upcoming release
* Code that is underspecified or low quality that becomes widely used (prawn-templates)
* Upstream dependencies
* Downstream dependencies
* Contributor involvement

Possible solutions:

* Always be release-ready
* Revert ruthlessly
* Favor extension points over new features to maintain
* Treat contributors as prospects, not commitments
* Keep test coverage and documentation high to reduce amount of information stored in the head.
* Automate processes for the same reason
* Don't be afraid to kill, simplify, or extract code that isn't stable and isn't feasible to stabilize.
* Limit dependencies on upstream resources, and understand how to estimate volatility.
* Proactive downstream outreach (Prawn extensions example) -- do it for selfish reasons




